# v0.2c Specification

> Async Architecture & Reliability

**Status**: Planned  
**Target**: Responsive UI, complete audit trail, robust error handling

---

## Overview

v0.2c addresses architectural issues that impact responsiveness, reliability, and debugging. This release refactors long-running operations to run in background tasks, ensures complete query logging, fixes empty result handling, validates configuration at startup, caches LLM prompts, and consolidates duplicated code.

---

## User Stories

### US-1: Responsive UI During Long Operations

> As a user, I want the UI to remain responsive while queries execute so I can cancel operations or continue reading results.

**Acceptance Criteria:**

- UI redraws continue during LLM/DB operations
- Ctrl+C or Esc cancels in-flight operations
- Spinner animation updates smoothly during execution
- Input remains responsive (can type while waiting)

### US-2: Complete Query History

> As a user, I want all executed queries to appear in the query log so I have a complete audit trail.

**Acceptance Criteria:**

- Auto-executed "safe" queries appear in query log
- Failed queries appear in query log with error indicator
- Query log shows both success and failure states
- Timestamps accurate for all entries

### US-3: Empty Result Headers

> As a user, I want to see column headers even when a query returns zero rows so I can verify my query structure.

**Acceptance Criteria:**

- Queries returning 0 rows display column names
- Column types shown in header (consistent with non-empty results)
- "No results" message appears below headers
- Execution time still displayed

### US-4: Clear Configuration Errors

> As a user, I want clear error messages when my configuration is invalid so I can fix issues quickly.

**Acceptance Criteria:**

- Invalid `llm.provider` value produces clear error at startup
- Error message lists valid provider options
- Application exits with non-zero status on config error
- No silent fallback to default provider

### US-5: Efficient LLM Requests

> As a user, I want the application to minimize token usage so I reduce LLM costs.

**Acceptance Criteria:**

- Schema prompt cached per connection (not rebuilt per request)
- Identical schema strings not duplicated in memory
- Token count reduced for repeated queries

### US-6: Consistent Command Palette

> As a user, I want the command palette to behave identically regardless of input mode.

**Acceptance Criteria:**

- Same key bindings work in Normal and Insert modes
- No behavioral drift between modes
- Single source of truth for palette handling

---

## Functional Requirements

### FR-1: Background Task Architecture

#### FR-1.1: Event Loop Refactor

Current state (`@/home/sophie/repos/glance/src/tui/mod.rs:294`):

```rust
match orchestrator.handle_input(&input).await {
```

The render loop directly awaits LLM/DB operations, blocking all UI updates.

**Refactor:**

- Spawn LLM and DB operations as background `tokio` tasks
- Main loop continues processing events (redraw, input, resize)
- Background tasks send results via `mpsc` channel
- Existing `AsyncMessage` enum extended for new message types

#### FR-1.2: Cancellation Support

- Track active operation with `tokio::task::JoinHandle`
- On cancel signal (Esc/Ctrl+C during operation):
  - Abort the background task
  - Send cancellation message to chat
  - Clear `is_processing` state
- Use `tokio_util::sync::CancellationToken` for cooperative cancellation

#### FR-1.3: Progress Channel

```rust
pub enum ProgressMessage {
    LlmStarted,
    LlmStreaming(String),  // Incremental token
    LlmComplete(String),   // Full response
    DbStarted,
    DbComplete(QueryResult),
    Error(String),
    Cancelled,
}
```

- Background tasks send progress updates
- UI updates spinner/status based on progress
- Enables future streaming output display

#### FR-1.4: Streaming LLM Output (Optional)

- Consume `LlmClient::complete_stream` when available
- Display tokens incrementally in chat panel
- Reduces perceived latency for long responses
- Graceful fallback if provider doesn't support streaming

---

### FR-2: Complete Query Logging

#### FR-2.1: Log Auto-Executed Queries

Current state (`@/home/sophie/repos/glance/src/tui/app.rs:252`): Query log entries created for confirmed queries but not for auto-executed safe queries.

**Fix:**

- Create `QueryLogEntry` for all executed queries
- Route entry back to TUI via `InputResult` or channel
- Include source indicator: `manual`, `generated`, `auto`

#### FR-2.2: Log Failed Queries

Current state (`@/home/sophie/repos/glance/src/tui/mod.rs:403`): `QueryLogEntry::error` constructor exists but is never called.

**Fix:**

- On query execution error, create error log entry
- Include error message in entry
- Display with distinct styling (red indicator)

#### FR-2.3: QueryLogEntry Enhancement

```rust
pub struct QueryLogEntry {
    pub sql: String,
    pub timestamp: Instant,
    pub status: QueryStatus,
    pub execution_time: Option<Duration>,
    pub row_count: Option<usize>,
    pub error_message: Option<String>,
    pub source: QuerySource,
}

pub enum QueryStatus {
    Success,
    Error,
    Cancelled,
}

pub enum QuerySource {
    Manual,      // /sql command
    Generated,   // LLM-generated, user-confirmed
    Auto,        // LLM-generated, auto-executed (safe)
}
```

---

### FR-3: Empty Result Column Metadata

#### FR-3.1: Capture Columns on Empty Results

Current state (`@/home/sophie/repos/glance/src/db/postgres.rs:118`):

```rust
if result.is_empty() {
    return Ok(QueryResult::new().with_execution_time(execution_time));
}
```

Returns empty `QueryResult` with no column information.

**Fix:**

- Use `sqlx::query(sql).describe(&self.pool)` or prepared statement to get column metadata
- Alternative: Execute query and capture `Row::columns()` even with 0 rows
- Populate `QueryResult.columns` regardless of row count

#### FR-3.2: Implementation Approach

```rust
async fn execute_query(&self, sql: &str) -> Result<QueryResult> {
    let start = Instant::now();

    // Fetch all rows
    let rows = sqlx::query(sql)
        .fetch_all(&self.pool)
        .await?;

    let execution_time = start.elapsed();

    // Get column metadata from query description if no rows
    let columns = if rows.is_empty() {
        // Use describe to get column info without rows
        let description = sqlx::query(sql)
            .describe(&self.pool)
            .await?;
        description.columns()
            .iter()
            .map(|c| ColumnInfo::new(c.name(), c.type_info().name()))
            .collect()
    } else {
        rows.first()
            .map(|row| /* existing column extraction */)
            .unwrap_or_default()
    };

    // ... rest of implementation
}
```

---

### FR-4: Provider Validation

#### FR-4.1: Validate at Startup

Current state (`@/home/sophie/repos/glance/src/main.rs:58`):

```rust
let llm_provider = config
    .llm
    .provider
    .parse::<LlmProvider>()
    .unwrap_or(LlmProvider::OpenAi);
```

Invalid provider silently falls back to OpenAI.

**Fix:**

```rust
let llm_provider = config
    .llm
    .provider
    .parse::<LlmProvider>()
    .map_err(|_| GlanceError::config(format!(
        "Invalid LLM provider '{}'. Valid options: openai, anthropic, ollama",
        config.llm.provider
    )))?;
```

#### FR-4.2: Error Message Format

```
Error: Invalid LLM provider 'opanai'. Valid options: openai, anthropic, ollama

Check your configuration file at ~/.config/glance/config.toml
```

- Suggest similar valid option if typo detected (optional)
- Show config file path for easy correction

---

### FR-5: Schema Prompt Caching

#### FR-5.1: Cache Formatted Schema

Current state (`@/home/sophie/repos/glance/src/llm/prompt.rs:26`):

```rust
pub fn build_system_prompt(schema: &Schema) -> String {
    let schema_text = schema.format_for_llm();
    SYSTEM_PROMPT_TEMPLATE.replace("{schema}", &schema_text)
}
```

Called on every LLM request, rebuilding identical string.

**Fix:**

- Cache formatted schema string in `Orchestrator` or dedicated cache
- Invalidate only on schema refresh (reconnect, explicit refresh)
- Use `Cow<str>` or `Arc<str>` to avoid cloning

#### FR-5.2: Implementation

```rust
pub struct PromptCache {
    schema_hash: u64,
    system_prompt: Arc<str>,
}

impl PromptCache {
    pub fn get_or_build(&mut self, schema: &Schema) -> Arc<str> {
        let hash = schema.content_hash();
        if hash != self.schema_hash {
            self.schema_hash = hash;
            self.system_prompt = Arc::from(build_system_prompt(schema));
        }
        Arc::clone(&self.system_prompt)
    }
}
```

#### FR-5.3: Benefits

- Reduces allocation per request
- Faster request assembly
- Lower memory churn
- Foundation for future schema pruning/segmentation

---

### FR-6: Command Palette Consolidation

#### FR-6.1: Extract Shared Handler

Current state: Command palette handling duplicated in:

- `@/home/sophie/repos/glance/src/tui/app.rs:721-764` (standard mode)
- `@/home/sophie/repos/glance/src/tui/app.rs:1126-1172` (insert mode)

**Fix:**

```rust
impl App {
    /// Handles command palette input. Returns true if event was consumed.
    fn handle_command_palette_key(&mut self, key: KeyEvent) -> bool {
        if !self.command_palette.visible {
            return false;
        }

        match key.code {
            KeyCode::Esc => self.command_palette.close(),
            KeyCode::Up => self.command_palette.select_previous(),
            KeyCode::Down => self.command_palette.select_next(),
            KeyCode::Tab => {
                if let Some(cmd) = self.command_palette.selected_command() {
                    self.input.text = format!("/{} ", cmd.name);
                    self.input.cursor = self.input.text.len();
                }
                self.command_palette.close();
            }
            KeyCode::Enter => {
                if let Some(cmd) = self.command_palette.selected_command() {
                    self.input.text = format!("/{} ", cmd.name);
                    self.input.cursor = self.input.text.len();
                }
                self.command_palette.close_and_submit();
            }
            KeyCode::Backspace => {
                if self.input.text.len() > 1 {
                    self.input.backspace();
                    let filter = self.input.text.strip_prefix('/').unwrap_or("");
                    self.command_palette.set_filter(filter);
                } else {
                    self.input.backspace();
                    self.command_palette.close();
                }
            }
            KeyCode::Char(c) => {
                self.input.insert(c);
                let filter = self.input.text.strip_prefix('/').unwrap_or("");
                self.command_palette.set_filter(filter);
            }
            _ => {}
        }
        true
    }
}
```

#### FR-6.2: Update Call Sites

```rust
fn handle_standard_input_key(&mut self, key: KeyEvent) {
    if self.handle_command_palette_key(key) {
        return;
    }
    // ... rest of standard mode handling
}

fn handle_insert_mode_key(&mut self, key: KeyEvent) {
    if self.handle_command_palette_key(key) {
        return;
    }
    // ... rest of insert mode handling
}
```

---

## Non-Functional Requirements

### NFR-1: Responsiveness

- UI frame rate maintained at 60fps during background operations
- Input latency < 16ms regardless of operation state
- Cancel signal processed within 100ms

### NFR-2: Memory Efficiency

- Cached schema prompt uses < 2x memory of raw schema
- No unbounded growth in progress channel
- Background task cleanup on cancellation

### NFR-3: Backward Compatibility

- No changes to config file format (validation only)
- Query log format unchanged (additions only)
- Existing keyboard shortcuts preserved

---

## Implementation Priority

| Issue                       | Value       | Effort | Priority |
| --------------------------- | ----------- | ------ | -------- |
| FR-1: Background Tasks      | High        | High   | 1        |
| FR-2: Query Logging         | Medium-High | Low    | 2        |
| FR-3: Empty Result Columns  | Medium      | Low    | 3        |
| FR-4: Provider Validation   | Medium      | Low    | 4        |
| FR-5: Schema Caching        | Medium      | Medium | 5        |
| FR-6: Palette Consolidation | Low-Medium  | Low    | 6        |

---

## Testing Strategy

### Unit Tests

- `PromptCache` correctly invalidates on schema change
- `QueryLogEntry` correctly captures all states
- Provider validation rejects invalid values

### Integration Tests

- Background task cancellation completes cleanly
- Empty result queries return column metadata
- Query log contains entries for all execution paths

### Manual Testing

- Verify UI responsiveness during slow queries
- Confirm cancel works mid-operation
- Check query log completeness after mixed operations

---

## Dependencies

- v0.2a and v0.2b must be complete
- `tokio_util` for `CancellationToken` (if not already present)
- No new external dependencies required

---

## Migration Notes

- No breaking changes
- Existing configs continue to work (invalid providers now error instead of fallback)
- Query log gains new fields (backward compatible)

---

## Open Questions

1. **Streaming granularity**: Should streaming output update per-token or batch tokens for efficiency?
   - _Proposed_: Batch with 50ms debounce for smooth display

2. **Cancel confirmation**: Should cancelling a mutation query require confirmation?
   - _Proposed_: No, cancel should be immediate (query may have already executed server-side)

3. **Schema cache invalidation**: Should there be a `/refresh` command to force schema reload?
   - _Proposed_: Yes, add `/refresh` command in future release

---

## Glossary

| Term               | Definition                                                  |
| ------------------ | ----------------------------------------------------------- |
| Background Task    | Async operation spawned separately from the main event loop |
| Cancellation Token | Cooperative cancellation mechanism for async tasks          |
| Progress Channel   | mpsc channel for sending operation status updates to UI     |
| Schema Cache       | In-memory cache of formatted schema string for LLM prompts  |
